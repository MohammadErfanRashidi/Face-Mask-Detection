{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install-kaggle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the Kaggle library to fetch datasets directly from Kaggle\n",
    "!pip install kaggle\n",
    "\n",
    "# Configure Kaggle API key for authentication\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json  # Secure the API key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c13ccd",
   "metadata": {},
   "source": [
    "### Step 1: Importing the Face Mask Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fetch-dataset",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Kaggle API to download the face mask dataset\n",
    "!kaggle datasets download -d omkargurav/face-mask-dataset\n",
    "\n",
    "# Unzip the downloaded dataset\n",
    "from zipfile import ZipFile\n",
    "dataset = '/content/face-mask-dataset.zip'\n",
    "\n",
    "with ZipFile(dataset, 'r') as zip:\n",
    "    zip.extractall()  # Extract contents to the current directory\n",
    "    print('The dataset has been extracted')\n",
    "\n",
    "# Verify the extracted files\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f443edb9",
   "metadata": {},
   "source": [
    "### Step 2: Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "import-libraries",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for data handling and processing\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "from google.colab.patches import cv2_imshow\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b3785d",
   "metadata": {},
   "source": [
    "### Step 3: Load and Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all files in the 'with_mask' directory\n",
    "with_mask_files = os.listdir('/content/data/with_mask')\n",
    "print(with_mask_files[0:5])  # Display first 5 file names\n",
    "print(with_mask_files[-5:])  # Display last 5 file names\n",
    "\n",
    "# List all files in the 'without_mask' directory\n",
    "without_mask_files = os.listdir('/content/data/without_mask')\n",
    "print(without_mask_files[0:5])\n",
    "print(without_mask_files[-5:])\n",
    "\n",
    "# Print the number of images in each category\n",
    "print('Number of with mask images:', len(with_mask_files))\n",
    "print('Number of without mask images:', len(without_mask_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fb29c2",
   "metadata": {},
   "source": [
    "### Step 4: Assign Labels to Images\n",
    "- **With Mask**: Label as `1`\n",
    "- **Without Mask**: Label as `0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-labels-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a label list for the two classes\n",
    "with_mask_labels = [1] * len(with_mask_files)  # Label all 'with mask' images as 1\n",
    "without_mask_labels = [0] * len(without_mask_files)  # Label all 'without mask' images as 0\n",
    "\n",
    "# Combine both label lists\n",
    "labels = with_mask_labels + without_mask_labels\n",
    "\n",
    "# Display label information\n",
    "print(len(labels))  # Total number of labels\n",
    "print(labels[0:5])  # First 5 labels\n",
    "print(labels[-5:])  # Last 5 labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a84257",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "display-samples",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a sample image from the 'with mask' category\n",
    "img = mpimg.imread('/content/data/with_mask/with_mask_1545.jpg')\n",
    "plt.imshow(img)\n",
    "plt.title('With Mask')\n",
    "plt.show()\n",
    "\n",
    "# Display a sample image from the 'without mask' category\n",
    "img = mpimg.imread('/content/data/without_mask/without_mask_2925.jpg')\n",
    "plt.imshow(img)\n",
    "plt.title('Without Mask')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce1ad15",
   "metadata": {},
   "source": [
    "### Step 6: Image Preprocessing\n",
    "- Resize all images to 128x128.\n",
    "- Convert to RGB format.\n",
    "- Convert images to numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "process-images-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory path for images\n",
    "with_mask_path = '/content/data/with_mask/'\n",
    "without_mask_path = '/content/data/without_mask/'\n",
    "\n",
    "data = []  # List to store processed image data\n",
    "\n",
    "# Process 'with mask' images\n",
    "for img_file in with_mask_files:\n",
    "    image = Image.open(with_mask_path + img_file)  # Open image\n",
    "    image = image.resize((128, 128))  # Resize to 128x128\n",
    "    image = image.convert('RGB')  # Convert to RGB\n",
    "    image = np.array(image)  # Convert to numpy array\n",
    "    data.append(image)\n",
    "\n",
    "# Process 'without mask' images\n",
    "for img_file in without_mask_files:\n",
    "    image = Image.open(without_mask_path + img_file)\n",
    "    image = image.resize((128, 128))\n",
    "    image = image.convert('RGB')\n",
    "    image = np.array(image)\n",
    "    data.append(image)\n",
    "\n",
    "# Convert data and labels to numpy arrays\n",
    "X = np.array(data)  # Image data\n",
    "Y = np.array(labels)  # Corresponding labels\n",
    "\n",
    "# Verify the shapes of the data arrays\n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94076a09",
   "metadata": {},
   "source": [
    "### Step 7: Train-Test Split\n",
    "- Split the data into training and testing sets.\n",
    "- Normalize the pixel values by scaling them between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training (80%) and testing (20%) sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)\n",
    "\n",
    "# Normalize pixel values by dividing by 255\n",
    "X_train_scaled = X_train / 255.0\n",
    "X_test_scaled = X_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dff433",
   "metadata": {},
   "source": [
    "### Step 8: Build and Train the CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cnn-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TensorFlow for building the model\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Define the CNN model architecture\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),  # First convolutional layer\n",
    "    keras.layers.MaxPooling2D(2, 2),  # First pooling layer\n",
    "    keras.layers.Conv2D(64, (3, 3), activation='relu'),  # Second convolutional layer\n",
    "    keras.layers.MaxPooling2D(2, 2),  # Second pooling layer\n",
    "    keras.layers.Flatten(),  # Flatten the feature maps\n",
    "    keras.layers.Dense(128, activation='relu'),  # Fully connected layer\n",
    "    keras.layers.Dropout(0.5),  # Dropout to prevent overfitting\n",
    "    keras.layers.Dense(2, activation='softmax')  # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model with the training data\n",
    "history = model.fit(X_train_scaled, Y_train, validation_split=0.1, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d6c2c9",
   "metadata": {},
   "source": [
    "### Step 9: Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "evaluate-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model performance on the test data\n",
    "loss, accuracy = model.evaluate(X_test_scaled, Y_test)\n",
    "print('Test Accuracy:', accuracy)\n",
    "\n",
    "# Plot the training and validation loss\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.title('Loss over Epochs')\n",
    "plt.show()\n",
    "\n",
    "# Plot the training and validation accuracy\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Accuracy over Epochs')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Face Mask Detection with Comments.ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
